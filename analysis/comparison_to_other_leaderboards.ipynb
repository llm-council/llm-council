{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb7a260-b42e-4326-84e8-a9147878e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source data: https://docs.google.com/spreadsheets/d/1Q6KiM2kosM1q1_NK-FzFjJ2o0mLS2YHe0sUkqTj6xbU/edit?gid=506716267#gid=506716267\n",
    "\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "data = \"\"\"LLM,System,Rank,Score\n",
    "qwen1.5-110B-Chat,LMC-EI (ours),1,65.6\n",
    "gpt-4o-2024-05-13,LMC-EI (ours),2,59.2\n",
    "claude-3-opus,LMC-EI (ours),3,50.1\n",
    "qwen1.5-32B-Chat,LMC-EI (ours),4,50\n",
    "llama-3-70b-chat,LMC-EI (ours),5,45.1\n",
    "claude-3-haiku,LMC-EI (ours),6,38.6\n",
    "mixtral-8x7b,LMC-EI (ours),7,34.4\n",
    "llama-3-8b-chat,LMC-EI (ours),8,30\n",
    "gpt-4-0613,LMC-EI (ours),9,44.2\n",
    "qwen1.5-110B-Chat,Human Study,3,53\n",
    "gpt-4o-2024-05-13,Human Study,2,54\n",
    "claude-3-opus,Human Study,1,55.7\n",
    "qwen1.5-32B-Chat,Human Study,4,50\n",
    "llama-3-70b-chat,Human Study,5,49.7\n",
    "claude-3-haiku,Human Study,6,49\n",
    "mixtral-8x7b,Human Study,7,48.9\n",
    "llama-3-8b-chat,Human Study,9,40\n",
    "gpt-4-0613,Human Study,8,43.9\n",
    "gpt-4o-2024-05-13,Chatbot Arena,1,1287\n",
    "gpt-4-0613,Chatbot Arena,3,1246\n",
    "mixtral-8x7b,Chatbot Arena,9,1114\n",
    "llama-3-70b-chat,Chatbot Arena,4,1208\n",
    "llama-3-8b-chat,Chatbot Arena,7,1153\n",
    "claude-3-opus,Chatbot Arena,2,1248\n",
    "claude-3-haiku,Chatbot Arena,5,1178\n",
    "qwen1.5-110B-Chat,Chatbot Arena,6,1164\n",
    "qwen1.5-32B-Chat,Chatbot Arena,8,1126\n",
    "gpt-4o-2024-05-13,MMLU,1,88.7\n",
    "gpt-4-0613,MMLU,3,86.4\n",
    "mixtral-8x7b,MMLU,8,70.6\n",
    "llama-3-70b-chat,MMLU,4,82.0\n",
    "llama-3-8b-chat,MMLU,9,68.4\n",
    "claude-3-opus,MMLU,2,86.8\n",
    "claude-3-haiku,MMLU,6,75.2\n",
    "qwen1.5-110B-Chat,MMLU,5,80.2\n",
    "qwen1.5-32B-Chat,MMLU,7,74.3\n",
    "gpt-4o-2024-05-13,EQ-Bench,3,83.51\n",
    "gpt-4-0613,EQ-Bench,1,84.79\n",
    "mixtral-8x7b,EQ-Bench,7,72.37\n",
    "llama-3-70b-chat,EQ-Bench,5,82.13\n",
    "llama-3-8b-chat,EQ-Bench,8,68.88\n",
    "claude-3-opus,EQ-Bench,4,82.19\n",
    "claude-3-haiku,EQ-Bench,9,63.65\n",
    "qwen1.5-110B-Chat,EQ-Bench,2,83.68\n",
    "qwen1.5-32B-Chat,EQ-Bench,6,75.59\n",
    "gpt-4o-2024-05-13,Chatbot Arena mined EQ subset (n=100),1,79.56\n",
    "gpt-4-0613,Chatbot Arena mined EQ subset (n=100),9,30.87\n",
    "mixtral-8x7b,Chatbot Arena mined EQ subset (n=100),8,37.62\n",
    "llama-3-70b-chat,Chatbot Arena mined EQ subset (n=100),2,77.21\n",
    "llama-3-8b-chat,Chatbot Arena mined EQ subset (n=100),4,53.69\n",
    "claude-3-opus,Chatbot Arena mined EQ subset (n=100),5,50.66\n",
    "claude-3-haiku,Chatbot Arena mined EQ subset (n=100),7,40.94\n",
    "qwen1.5-110B-Chat,Chatbot Arena mined EQ subset (n=100),3,69.35\n",
    "qwen1.5-32B-Chat,Chatbot Arena mined EQ subset (n=100),6,50\"\"\"\n",
    "\n",
    "df = pd.read_csv(StringIO(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08620de0-1f65-4f61-b865-6e1739329ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print correlations\n",
    "pivot_df = df.pivot(index='LLM', columns='System', values='Score')\n",
    "spearman_corr = pivot_df.corr(method='spearman')\n",
    "\n",
    "# Reorder the matrix to have 'Human Study' last\n",
    "system_order = ['EQ-Bench', 'Chatbot Arena', 'Chatbot Arena mined EQ subset (n=100)', 'MMLU', 'LMC-EI (ours)', 'Human Study']\n",
    "spearman_corr = spearman_corr.loc[system_order, system_order]\n",
    "spearman_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74618650-ae98-486d-a13c-a12cb69ce48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a custom annotation DataFrame\n",
    "annot = spearman_corr.copy().astype(str)\n",
    "\n",
    "# Apply the custom style to the annotations\n",
    "for i in spearman_corr.index:\n",
    "    for j in spearman_corr.columns:\n",
    "        value = spearman_corr.loc[i, j]\n",
    "        # if i == 'Human Study' or j == 'Human Study':\n",
    "        if i == 'Human Study':\n",
    "            annot.loc[i, j] = f'$\\mathbf{{{value:.2f}}}$'\n",
    "        else:\n",
    "            annot.loc[i, j] = f'{value:.2f}'\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(15, 13))\n",
    "sns.heatmap(spearman_corr, annot=annot, cmap='coolwarm', linewidths=3, fmt='',\n",
    "            annot_kws={\"size\": 14}, cbar_kws={'label': 'Spearman Correlation'})\n",
    "\n",
    "# Modify the axis labels to bold \"Human Study\"\n",
    "ax = plt.gca()  # Get the current axis\n",
    "\n",
    "# Bold the 'Human Study' label on the x-axis\n",
    "# Bold the 'Human Study' label on the y-axis\n",
    "labels = [item.get_text() for item in ax.get_yticklabels()]\n",
    "ax.set_yticklabels([f'$\\mathbf{{{label}}}$' if label == 'Human Study' else label for label in labels], fontsize=14, rotation=0)\n",
    "\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xticks(fontsize=14, rotation=90)\n",
    "plt.yticks(fontsize=14, rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/Users/justinzhao/Repos/llm-council-public/analysis/leaderboard_comparison.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4150cd03-61fc-4413-9022-0e0048d486aa",
   "metadata": {},
   "source": [
    "## Individual Judges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2aa2bb-499e-4ade-af01-8c20f5e7a4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source data: https://docs.google.com/spreadsheets/d/1Q6KiM2kosM1q1_NK-FzFjJ2o0mLS2YHe0sUkqTj6xbU/edit?gid=506716267#gid=506716267\n",
    "\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "data = \"\"\"LLM,System,Rank,Score\n",
    "qwen1.5-110B-Chat,Human Study,3,53\n",
    "gpt-4o-2024-05-13,Human Study,2,54\n",
    "claude-3-opus,Human Study,1,55.7\n",
    "qwen1.5-32B-Chat,Human Study,4,50\n",
    "llama-3-70b-chat,Human Study,5,49.7\n",
    "claude-3-haiku,Human Study,6,49\n",
    "mixtral-8x7b,Human Study,7,48.9\n",
    "llama-3-8b-chat,Human Study,9,40\n",
    "gpt-4-0613,Human Study,8,43.9\n",
    "gpt-4o-2024-05-13,Chatbot Arena,1,1287\n",
    "gpt-4-0613,Chatbot Arena,3,1246\n",
    "mixtral-8x7b,Chatbot Arena,9,1114\n",
    "llama-3-70b-chat,Chatbot Arena,4,1208\n",
    "llama-3-8b-chat,Chatbot Arena,7,1153\n",
    "claude-3-opus,Chatbot Arena,2,1248\n",
    "claude-3-haiku,Chatbot Arena,5,1178\n",
    "qwen1.5-110B-Chat,Chatbot Arena,6,1164\n",
    "qwen1.5-32B-Chat,Chatbot Arena,8,1126\n",
    "gpt-4o-2024-05-13,MMLU,1,88.7\n",
    "gpt-4-0613,MMLU,3,86.4\n",
    "mixtral-8x7b,MMLU,8,70.6\n",
    "llama-3-70b-chat,MMLU,4,82.0\n",
    "llama-3-8b-chat,MMLU,9,68.4\n",
    "claude-3-opus,MMLU,2,86.8\n",
    "claude-3-haiku,MMLU,6,75.2\n",
    "qwen1.5-110B-Chat,MMLU,5,80.2\n",
    "qwen1.5-32B-Chat,MMLU,7,74.3\n",
    "gpt-4o-2024-05-13,EQ-Bench,3,83.5\n",
    "gpt-4-0613,EQ-Bench,1,84.8\n",
    "mixtral-8x7b,EQ-Bench,7,72.4\n",
    "llama-3-70b-chat,EQ-Bench,5,82.1\n",
    "llama-3-8b-chat,EQ-Bench,8,68.9\n",
    "claude-3-opus,EQ-Bench,4,82.2\n",
    "claude-3-haiku,EQ-Bench,9,63.7\n",
    "qwen1.5-110B-Chat,EQ-Bench,2,83.7\n",
    "qwen1.5-32B-Chat,EQ-Bench,6,75.6\n",
    "gpt-4o-2024-05-13,Chatbot Arena mined EQ subset (n=100),1,79.56\n",
    "gpt-4-0613,Chatbot Arena mined EQ subset (n=100),9,30.87\n",
    "mixtral-8x7b,Chatbot Arena mined EQ subset (n=100),8,37.62\n",
    "llama-3-70b-chat,Chatbot Arena mined EQ subset (n=100),2,77.21\n",
    "llama-3-8b-chat,Chatbot Arena mined EQ subset (n=100),4,53.69\n",
    "claude-3-opus,Chatbot Arena mined EQ subset (n=100),5,50.66\n",
    "claude-3-haiku,Chatbot Arena mined EQ subset (n=100),7,40.94\n",
    "qwen1.5-110B-Chat,Chatbot Arena mined EQ subset (n=100),3,69.35\n",
    "qwen1.5-32B-Chat,Chatbot Arena mined EQ subset (n=100),6,50\n",
    "qwen1.5-110B-Chat,LMC-EI (llama-3-70b-chat),1,70.53\n",
    "gpt-4o-2024-05-13,LMC-EI (llama-3-70b-chat),2,65.38\n",
    "llama-3-70b-chat,LMC-EI (llama-3-70b-chat),3,56.36\n",
    "claude-3-opus,LMC-EI (llama-3-70b-chat),4,51.64\n",
    "qwen1.5-32B-Chat,LMC-EI (llama-3-70b-chat),5,50\n",
    "claude-3-haiku,LMC-EI (llama-3-70b-chat),6,38.66\n",
    "llama-3-8b-chat,LMC-EI (llama-3-70b-chat),7,29.77\n",
    "mixtral-8x7b,LMC-EI (llama-3-70b-chat),8,26.74\n",
    "gpt-4-0613,LMC-EI (llama-3-70b-chat),9,16.9\n",
    "qwen1.5-110B-Chat,LMC-EI (qwen1.5-110B-Chat),1,68.63\n",
    "gpt-4o-2024-05-13,LMC-EI (qwen1.5-110B-Chat),2,55.5\n",
    "qwen1.5-32B-Chat,LMC-EI (qwen1.5-110B-Chat),3,50\n",
    "claude-3-opus,LMC-EI (qwen1.5-110B-Chat),4,45.5\n",
    "llama-3-70b-chat,LMC-EI (qwen1.5-110B-Chat),5,35.78\n",
    "mixtral-8x7b,LMC-EI (qwen1.5-110B-Chat),6,31.68\n",
    "claude-3-haiku,LMC-EI (qwen1.5-110B-Chat),7,23.35\n",
    "llama-3-8b-chat,LMC-EI (qwen1.5-110B-Chat),8,19.58\n",
    "gpt-4-0613,LMC-EI (qwen1.5-110B-Chat),9,18.87\n",
    "llama-3-70b-chat,LMC-EI (llama-3-8b-chat),1,62.65\n",
    "qwen1.5-110B-Chat,LMC-EI (llama-3-8b-chat),2,58.53\n",
    "gpt-4o-2024-05-13,LMC-EI (llama-3-8b-chat),3,52.24\n",
    "llama-3-8b-chat,LMC-EI (llama-3-8b-chat),4,51.27\n",
    "claude-3-opus,LMC-EI (llama-3-8b-chat),5,50.92\n",
    "qwen1.5-32B-Chat,LMC-EI (llama-3-8b-chat),6,50\n",
    "claude-3-haiku,LMC-EI (llama-3-8b-chat),7,48.82\n",
    "mixtral-8x7b,LMC-EI (llama-3-8b-chat),8,43.03\n",
    "gpt-4-0613,LMC-EI (llama-3-8b-chat),9,33.23\n",
    "qwen1.5-110B-Chat,LMC-EI (gpt-4-0613),1,68\n",
    "gpt-4o-2024-05-13,LMC-EI (gpt-4-0613),2,59.25\n",
    "qwen1.5-32B-Chat,LMC-EI (gpt-4-0613),3,50\n",
    "claude-3-opus,LMC-EI (gpt-4-0613),4,43\n",
    "llama-3-70b-chat,LMC-EI (gpt-4-0613),5,38.12\n",
    "claude-3-haiku,LMC-EI (gpt-4-0613),6,28.19\n",
    "mixtral-8x7b,LMC-EI (gpt-4-0613),7,25.96\n",
    "gpt-4-0613,LMC-EI (gpt-4-0613),8,20.79\n",
    "llama-3-8b-chat,LMC-EI (gpt-4-0613),9,14.22\n",
    "qwen1.5-110B-Chat,LMC-EI (claude-3-opus),1,77\n",
    "gpt-4o-2024-05-13,LMC-EI (claude-3-opus),2,59.25\n",
    "qwen1.5-32B-Chat,LMC-EI (claude-3-opus),3,50\n",
    "claude-3-opus,LMC-EI (claude-3-opus),4,42.5\n",
    "claude-3-haiku,LMC-EI (claude-3-opus),5,35\n",
    "llama-3-70b-chat,LMC-EI (claude-3-opus),6,26.5\n",
    "mixtral-8x7b,LMC-EI (claude-3-opus),7,23.75\n",
    "gpt-4-0613,LMC-EI (claude-3-opus),8,18.14\n",
    "llama-3-8b-chat,LMC-EI (claude-3-opus),9,9\n",
    "qwen1.5-110B-Chat,LMC-EI (mixtral-8x7b),1,69.42\n",
    "gpt-4o-2024-05-13,LMC-EI (mixtral-8x7b),2,67.16\n",
    "llama-3-70b-chat,LMC-EI (mixtral-8x7b),2,67.16\n",
    "claude-3-opus,LMC-EI (mixtral-8x7b),3,63.81\n",
    "qwen1.5-32B-Chat,LMC-EI (mixtral-8x7b),4,50\n",
    "llama-3-8b-chat,LMC-EI (mixtral-8x7b),5,44.86\n",
    "claude-3-haiku,LMC-EI (mixtral-8x7b),6,43.69\n",
    "mixtral-8x7b,LMC-EI (mixtral-8x7b),7,41.28\n",
    "gpt-4-0613,LMC-EI (mixtral-8x7b),8,34.43\n",
    "gpt-4o-2024-05-13,LMC-EI (gpt-4o-2024-05-13),1,67.42\n",
    "qwen1.5-110B-Chat,LMC-EI (gpt-4o-2024-05-13),2,62.31\n",
    "qwen1.5-32B-Chat,LMC-EI (gpt-4o-2024-05-13),3,50\n",
    "llama-3-70b-chat,LMC-EI (gpt-4o-2024-05-13),4,43.02\n",
    "claude-3-opus,LMC-EI (gpt-4o-2024-05-13),5,41.67\n",
    "mixtral-8x7b,LMC-EI (gpt-4o-2024-05-13),6,29.55\n",
    "claude-3-haiku,LMC-EI (gpt-4o-2024-05-13),7,26.15\n",
    "gpt-4-0613,LMC-EI (gpt-4o-2024-05-13),8,23.36\n",
    "llama-3-8b-chat,LMC-EI (gpt-4o-2024-05-13),9,19.66\n",
    "qwen1.5-110B-Chat,LMC-EI (claude-3-haiku),1,61\n",
    "claude-3-opus,LMC-EI (claude-3-haiku),2,55.5\n",
    "llama-3-70b-chat,LMC-EI (claude-3-haiku),3,53\n",
    "gpt-4o-2024-05-13,LMC-EI (claude-3-haiku),4,52.97\n",
    "qwen1.5-32B-Chat,LMC-EI (claude-3-haiku),5,50\n",
    "claude-3-haiku,LMC-EI (claude-3-haiku),6,46.08\n",
    "llama-3-8b-chat,LMC-EI (claude-3-haiku),7,42.5\n",
    "mixtral-8x7b,LMC-EI (claude-3-haiku),8,37.62\n",
    "gpt-4-0613,LMC-EI (claude-3-haiku),9,33.65\n",
    "qwen1.5-110B-Chat,LMC-EI (council.mean_pooling),1,65.75\n",
    "gpt-4o-2024-05-13,LMC-EI (council.mean_pooling),2,58.5\n",
    "claude-3-opus,LMC-EI (council.mean_pooling),3,51.25\n",
    "qwen1.5-32B-Chat,LMC-EI (council.mean_pooling),4,50\n",
    "llama-3-70b-chat,LMC-EI (council.mean_pooling),5,46.25\n",
    "claude-3-haiku,LMC-EI (council.mean_pooling),6,36.75\n",
    "mixtral-8x7b,LMC-EI (council.mean_pooling),7,32.75\n",
    "llama-3-8b-chat,LMC-EI (council.mean_pooling),8,30\n",
    "gpt-4-0613,LMC-EI (council.mean_pooling),9,23.53\n",
    "qwen1.5-110B-Chat,LMC-EI (council.majority),1,78\n",
    "gpt-4o-2024-05-13,LMC-EI (council.majority),2,68\n",
    "qwen1.5-32B-Chat,LMC-EI (council.majority),3,50\n",
    "claude-3-opus,LMC-EI (council.majority),4,47\n",
    "llama-3-70b-chat,LMC-EI (council.majority),5,36.5\n",
    "claude-3-haiku,LMC-EI (council.majority),6,27.5\n",
    "mixtral-8x7b,LMC-EI (council.majority),7,21.5\n",
    "gpt-4-0613,LMC-EI (council.majority),8,14.71\n",
    "llama-3-8b-chat,LMC-EI (council.majority),9,13\n",
    "qwen1.5-110B-Chat,LMC-EI (council.no_agg),1,65.62\n",
    "gpt-4o-2024-05-13,LMC-EI (council.no_agg),2,59.19\n",
    "claude-3-opus,LMC-EI (council.no_agg),3,50.09\n",
    "qwen1.5-32B-Chat,LMC-EI (council.no_agg),4,50\n",
    "llama-3-70b-chat,LMC-EI (council.no_agg),5,45.08\n",
    "claude-3-haiku,LMC-EI (council.no_agg),6,38.59\n",
    "mixtral-8x7b,LMC-EI (council.no_agg),7,34.45\n",
    "llama-3-8b-chat,LMC-EI (council.no_agg),8,30.04\n",
    "gpt-4-0613,LMC-EI (council.no_agg),9,44.2\n",
    "qwen1.5-110B-Chat,LMC-EI (best_council.no_agg),1,68.1\n",
    "gpt-4o-2024-05-13,LMC-EI (best_council.no_agg),2,65.45\n",
    "qwen1.5-32B-Chat,LMC-EI (best_council.no_agg),3,50\n",
    "claude-3-opus,LMC-EI (best_council.no_agg),4,42.91\n",
    "llama-3-70b-chat,LMC-EI (best_council.no_agg),5,38.75\n",
    "claude-3-haiku,LMC-EI (best_council.no_agg),6,31.98\n",
    "mixtral-8x7b,LMC-EI (best_council.no_agg),7,29.5\n",
    "gpt-4-0613,LMC-EI (best_council.no_agg),8,24.55\n",
    "llama-3-8b-chat,LMC-EI (best_council.no_agg),9,20.02\n",
    "qwen1.5-110B-Chat,LMC-EI (flagships_council.no_agg),1,69.49\n",
    "gpt-4o-2024-05-13,LMC-EI (flagships_council.no_agg),2,62.78\n",
    "qwen1.5-32B-Chat,LMC-EI (flagships_council.no_agg),3,50\n",
    "claude-3-opus,LMC-EI (flagships_council.no_agg),4,46.32\n",
    "llama-3-70b-chat,LMC-EI (flagships_council.no_agg),5,40.57\n",
    "claude-3-haiku,LMC-EI (flagships_council.no_agg),6,33.1\n",
    "mixtral-8x7b,LMC-EI (flagships_council.no_agg),7,28.76\n",
    "gpt-4-0613,LMC-EI (flagships_council.no_agg),8,21.24\n",
    "llama-3-8b-chat,LMC-EI (flagships_council.no_agg),9,21.11\n",
    "qwen1.5-110B-Chat,LMC-EI (smallest_council.no_agg),1,59.52\n",
    "claude-3-opus,LMC-EI (smallest_council.no_agg),2,53.46\n",
    "gpt-4o-2024-05-13,LMC-EI (smallest_council.no_agg),3,53.39\n",
    "llama-3-70b-chat,LMC-EI (smallest_council.no_agg),4,51.39\n",
    "qwen1.5-32B-Chat,LMC-EI (smallest_council.no_agg),5,50\n",
    "claude-3-haiku,LMC-EI (smallest_council.no_agg),6,44.75\n",
    "llama-3-8b-chat,LMC-EI (smallest_council.no_agg),7,39.81\n",
    "mixtral-8x7b,LMC-EI (smallest_council.no_agg),8,39.22\n",
    "gpt-4-0613,LMC-EI (smallest_council.no_agg),9,31.48\n",
    "qwen1.5-110B-Chat,LMC-EI (qwen1.5-72B-Chat),1,63.45\n",
    "claude-3-opus,LMC-EI (qwen1.5-72B-Chat),2,58.55\n",
    "gpt-4o-2024-05-13,LMC-EI (qwen1.5-72B-Chat),3,50.43\n",
    "qwen1.5-32B-Chat,LMC-EI (qwen1.5-72B-Chat),4,50\n",
    "llama-3-70b-chat,LMC-EI (qwen1.5-72B-Chat),5,46.43\n",
    "claude-3-haiku,LMC-EI (qwen1.5-72B-Chat),6,43.3\n",
    "llama-3-8b-chat,LMC-EI (qwen1.5-72B-Chat),7,40.83\n",
    "mixtral-8x7b,LMC-EI (qwen1.5-72B-Chat),8,40.43\n",
    "gpt-4-0613,LMC-EI (qwen1.5-72B-Chat),9,33.06\n",
    "qwen1.5-110B-Chat,LMC-EI (command-r-plus),1,64.85\n",
    "gpt-4o-2024-05-13,LMC-EI (command-r-plus),2,59.65\n",
    "qwen1.5-32B-Chat,LMC-EI (command-r-plus),3,50\n",
    "claude-3-opus,LMC-EI (command-r-plus),4,48.5\n",
    "llama-3-70b-chat,LMC-EI (command-r-plus),5,43.56\n",
    "claude-3-haiku,LMC-EI (command-r-plus),6,42.57\n",
    "mixtral-8x7b,LMC-EI (command-r-plus),7,34.16\n",
    "llama-3-8b-chat,LMC-EI (command-r-plus),8,25.74\n",
    "gpt-4-0613,LMC-EI (command-r-plus),9,19.16\n",
    "qwen1.5-110B-Chat,LMC-EI (gemini-1.5-pro),1,72.25\n",
    "gpt-4o-2024-05-13,LMC-EI (gemini-1.5-pro),2,70.25\n",
    "qwen1.5-32B-Chat,LMC-EI (gemini-1.5-pro),3,50\n",
    "claude-3-opus,LMC-EI (gemini-1.5-pro),4,45.79\n",
    "llama-3-70b-chat,LMC-EI (gemini-1.5-pro),5,44\n",
    "claude-3-haiku,LMC-EI (gemini-1.5-pro),6,36.63\n",
    "gpt-4-0613,LMC-EI (gemini-1.5-pro),7,30.24\n",
    "mixtral-8x7b,LMC-EI (gemini-1.5-pro),8,29.95\n",
    "llama-3-8b-chat,LMC-EI (gemini-1.5-pro),9,27.72\n",
    "qwen1.5-110B-Chat,LMC-EI (qwen1.5-32B-Chat),1,56.14\n",
    "claude-3-opus,LMC-EI (qwen1.5-32B-Chat),2,54.36\n",
    "qwen1.5-32B-Chat,LMC-EI (qwen1.5-32B-Chat),3,50\n",
    "mixtral-8x7b,LMC-EI (qwen1.5-32B-Chat),4,47.99\n",
    "gpt-4o-2024-05-13,LMC-EI (qwen1.5-32B-Chat),5,47.54\n",
    "claude-3-haiku,LMC-EI (qwen1.5-32B-Chat),6,47.35\n",
    "llama-3-70b-chat,LMC-EI (qwen1.5-32B-Chat),7,42.46\n",
    "llama-3-8b-chat,LMC-EI (qwen1.5-32B-Chat),8,37.61\n",
    "gpt-4-0613,LMC-EI (qwen1.5-32B-Chat),9,33.79\n",
    "qwen1.5-110B-Chat,LMC-EI (gemini-1.0-pro),1,60.05\n",
    "gpt-4o-2024-05-13,LMC-EI (gemini-1.0-pro),2,51.44\n",
    "qwen1.5-32B-Chat,LMC-EI (gemini-1.0-pro),3,50\n",
    "claude-3-opus,LMC-EI (gemini-1.0-pro),4,49.3\n",
    "claude-3-haiku,LMC-EI (gemini-1.0-pro),5,45.63\n",
    "llama-3-70b-chat,LMC-EI (gemini-1.0-pro),6,42.89\n",
    "mixtral-8x7b,LMC-EI (gemini-1.0-pro),7,40.2\n",
    "gpt-4-0613,LMC-EI (gemini-1.0-pro),8,35.88\n",
    "llama-3-8b-chat,LMC-EI (gemini-1.0-pro),9,34.22\n",
    "qwen1.5-110B-Chat,LMC-EI (gpt-3.5-turbo-0125),1,75.36\n",
    "gpt-4o-2024-05-13,LMC-EI (gpt-3.5-turbo-0125),2,68.08\n",
    "claude-3-opus,LMC-EI (gpt-3.5-turbo-0125),3,50.76\n",
    "qwen1.5-32B-Chat,LMC-EI (gpt-3.5-turbo-0125),4,50\n",
    "llama-3-70b-chat,LMC-EI (gpt-3.5-turbo-0125),5,40.48\n",
    "mixtral-8x7b,LMC-EI (gpt-3.5-turbo-0125),6,34.46\n",
    "claude-3-haiku,LMC-EI (gpt-3.5-turbo-0125),7,33.46\n",
    "gpt-4-0613,LMC-EI (gpt-3.5-turbo-0125),8,29.79\n",
    "llama-3-8b-chat,LMC-EI (gpt-3.5-turbo-0125),9,28.08\n",
    "qwen1.5-110B-Chat,LMC-EI (dbrx-instruct),1,61\n",
    "gpt-4o-2024-05-13,LMC-EI (dbrx-instruct),2,57.5\n",
    "claude-3-opus,LMC-EI (dbrx-instruct),3,50.25\n",
    "qwen1.5-32B-Chat,LMC-EI (dbrx-instruct),4,50\n",
    "claude-3-haiku,LMC-EI (dbrx-instruct),5,45.39\n",
    "llama-3-70b-chat,LMC-EI (dbrx-instruct),6,40.93\n",
    "mixtral-8x7b,LMC-EI (dbrx-instruct),7,34.52\n",
    "gpt-4-0613,LMC-EI (dbrx-instruct),8,31.6\n",
    "llama-3-8b-chat,LMC-EI (dbrx-instruct),9,28.19\"\"\"\n",
    "\n",
    "df = pd.read_csv(StringIO(data))\n",
    "\n",
    "\n",
    "# Get correlations.\n",
    "pivot_df = df.pivot(index='LLM', columns='System', values='Score')\n",
    "spearman_corr = pivot_df.corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a152f85b-4693-4f75-8270-bb9416308c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b1d9aa-d4bc-45ae-8c04-b09147071f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spearman_corr\n",
    "spearman_corr[\"Human Study\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656d9b42-8f6e-41f7-8b0a-0bf59fc85009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Sample data - replace this with your actual pandas Series\n",
    "data = spearman_corr[\"Human Study\"].sort_values(ascending=False)\n",
    "\n",
    "# Define a color mapping function\n",
    "def get_color(key):\n",
    "    if \"council\" in key:\n",
    "        return 'lightblue'\n",
    "    elif \"LMC\" in key:\n",
    "        return \"tab:blue\"\n",
    "    elif \"mined\" in key:\n",
    "        return \"tab:purple\"\n",
    "    elif \"EQ-Bench\" in key:\n",
    "        return 'tab:green'\n",
    "    elif \"MMLU\" in key:\n",
    "        return 'red'\n",
    "    elif \"Chatbot Arena\" in key:\n",
    "        return 'tab:purple'\n",
    "    else:\n",
    "        return 'gray'  # default color for other bars\n",
    "\n",
    "# Apply the color mapping function to the index\n",
    "colors = [get_color(key) for key in data.index]\n",
    "\n",
    "# Create the bar plot with horizontal bars\n",
    "plt.figure(figsize=(12, 8))  # Increase width to prevent cutoff\n",
    "ax = sns.barplot(x=data.values, y=data.index, palette=colors)\n",
    "\n",
    "# Add labels to each bar\n",
    "for i in range(len(data)):\n",
    "    ax.text(data.values[i], i, f'{data.values[i]:.3f}', color='black', ha='left', va='center')\n",
    "\n",
    "# Set labels\n",
    "plt.xlabel('')\n",
    "plt.ylabel('System')\n",
    "plt.title('Spearman correlation with EI Human Study')\n",
    "\n",
    "# Adjust the horizontal axis limits to expand space (customize this as needed)\n",
    "plt.xlim(0, data.max() * 1.1)  # Adds 10% padding on the right\n",
    "\n",
    "# Create a custom legend\n",
    "legend_labels = {\n",
    "    'LMC-EI (council), in-domain': 'lightblue',\n",
    "    'LMC-EI (single judge), in-domain': 'tab:blue',\n",
    "    'EQ-Bench': 'tab:green',\n",
    "    'MMLU': 'red',\n",
    "    'Chatbot Arena': 'tab:purple',\n",
    "    # 'Chatbot Arena (EI subset)': 'tab:purple',\n",
    "}\n",
    "\n",
    "# Create patches for each label\n",
    "legend_patches = [mpatches.Patch(color=color, label=label) for label, color in legend_labels.items()]\n",
    "\n",
    "# Add the legend to the plot\n",
    "plt.legend(handles=legend_patches, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Use tight layout to ensure everything fits\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig(\"/Users/justinzhao/Repos/llm-council-public/analysis/leaderboard_comparison_expanded.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32611f79-49e5-4e74-a759-a5e39099c739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

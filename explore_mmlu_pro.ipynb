{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38950b98-3e7b-47d1-a4e2-66dc1e75e66b",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf10c95-8321-4a0a-8ece-7f1274b02e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"sam-paech/mmlu-pro-nomath-sml\")\n",
    "df_ground_truth = dataset[\"test\"].to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a517353-4807-4482-9b77-d177b19cd5da",
   "metadata": {},
   "source": [
    "# Experiment: Generate requests and collect responses in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dd5c5d-5bc3-4d4c-9d66-2fc132fae600",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4793e936-d61b-4423-8087-619b91baedc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import os\n",
    "\n",
    "from llm_council.constants import LLM_COUNCIL_MEMBERS\n",
    "from llm_council.processors.council_service import (\n",
    "    get_default_council_service,\n",
    "    CouncilService,\n",
    ")\n",
    "from mmlu_prompts import (\n",
    "    STRUCTURED_OUTPUT_JUDGE_GROUND_TRUTH_COT_FIRST,\n",
    "    STRUCTURED_OUTPUT_JUDGE_GROUND_TRUTH_COT_SECOND,\n",
    "    STRUCTURED_OUTPUT_JUDGE_GROUND_TRUTH_NO_COT,\n",
    "    PROMPT_JUDGE_GROUND_TRUTH_COT_FIRST,\n",
    "    PROMPT_JUDGE_GROUND_TRUTH_COT_SECOND,\n",
    "    PROMPT_JUDGE_GROUND_TRUTH_NO_COT,\n",
    "    PROMPT_ANSWER_COT_FIRST,\n",
    "    PROMPT_ANSWER_COT_SECOND,\n",
    "    PROMPT_ANSWER_NO_COT,\n",
    "    STRUCTURED_OUTPUT_ANSWER_COT_FIRST,\n",
    "    STRUCTURED_OUTPUT_ANSWER_COT_SECOND,\n",
    "    STRUCTURED_OUTPUT_ANSWER_NO_COT\n",
    ")\n",
    "\n",
    "# OUTDIR = \"data_mmlu/mmlu_pro.n100.mini.run2\"\n",
    "NUM_EXAMPLES = 100 # Change this to None to use the full set.\n",
    "MODEL = \"lepton://llama3-2-3b\"\n",
    "BASE_OUTDIR = f\"data_mmlu/mmlu_pro.{f'n{NUM_EXAMPLES}' if NUM_EXAMPLES else 'full'}.lepton\"\n",
    "NUM_RUNS = 3\n",
    "\n",
    "assert MODEL in LLM_COUNCIL_MEMBERS\n",
    "\n",
    "CHOICE_MAP = {\n",
    "    0: \"A\",\n",
    "    1: \"B\",\n",
    "    2: \"C\",\n",
    "    3: \"D\",\n",
    "    4: \"E\",\n",
    "    5: \"F\",\n",
    "    6: \"G\",\n",
    "    7: \"H\",\n",
    "    8: \"I\",\n",
    "    9: \"J\",\n",
    "    10: \"K\", \n",
    "    11: \"L\", \n",
    "    12: \"M\",\n",
    "}\n",
    "\n",
    "PROMPT_MAP = {\n",
    "    \"so_jgt_cot1\": STRUCTURED_OUTPUT_JUDGE_GROUND_TRUTH_COT_FIRST,\n",
    "    \"so_jgt_cot2\": STRUCTURED_OUTPUT_JUDGE_GROUND_TRUTH_COT_SECOND,\n",
    "    \"so_jgt_cot0\": STRUCTURED_OUTPUT_JUDGE_GROUND_TRUTH_NO_COT,\n",
    "    \"pr_jgt_cot1\": PROMPT_JUDGE_GROUND_TRUTH_COT_FIRST,\n",
    "    \"pr_jgt_cot2\": PROMPT_JUDGE_GROUND_TRUTH_COT_SECOND,\n",
    "    \"pr_jgt_cot0\": PROMPT_JUDGE_GROUND_TRUTH_NO_COT,\n",
    "    \"pr_ans_cot1\": PROMPT_ANSWER_COT_FIRST,\n",
    "    \"pr_ans_cot2\": PROMPT_ANSWER_COT_SECOND,\n",
    "    \"pr_ans_cot0\": PROMPT_ANSWER_NO_COT,\n",
    "    \"so_ans_cot1\": STRUCTURED_OUTPUT_ANSWER_COT_FIRST,\n",
    "    \"so_ans_cot2\": STRUCTURED_OUTPUT_ANSWER_COT_SECOND,\n",
    "    \"so_ans_cot0\": STRUCTURED_OUTPUT_ANSWER_NO_COT,\n",
    "}\n",
    "\n",
    "\n",
    "def get_options_string(options):\n",
    "    str = \"\"\n",
    "    option_strings = []\n",
    "    for i, option in enumerate(options):\n",
    "        option_strings.append(f\"{CHOICE_MAP[i]}: {option}\")\n",
    "    return \", \".join(option_strings)\n",
    "    \n",
    "\n",
    "def get_answer_string(options, answer_index):\n",
    "    return CHOICE_MAP[answer_index] + \": \" + options[answer_index]\n",
    "\n",
    "\n",
    "def generate_requests(\n",
    "    prompt_name: int,\n",
    "    should_judge_ground_truth: bool,\n",
    "    temperature: float,\n",
    "    schema_name: str = None,\n",
    "    role: str = None,\n",
    "    run: int = 0\n",
    "):\n",
    "    base_prompt = PROMPT_MAP[prompt_name]\n",
    "    outdir = os.path.join(\n",
    "        \".\".join([BASE_OUTDIR, f\"run{run}\"]), \n",
    "        \".\".join([\n",
    "            prompt_name,\n",
    "            # \"judge_ground_truth\" if should_judge_ground_truth else \"answer\",\n",
    "            schema_name if schema_name else \"no_schema\",\n",
    "            f\"temp{temperature}\",\n",
    "            role if role else \"no_role\",\n",
    "    ]))\n",
    "    \n",
    "    council_service = CouncilService(\n",
    "        llm_council_members=[\n",
    "            MODEL\n",
    "            # \"openai://gpt-4o-mini-2024-07-18\", \n",
    "            # \"openai://gpt-4o-2024-08-06\",\n",
    "        ],\n",
    "        outdir=outdir,\n",
    "    )\n",
    "\n",
    "    if NUM_EXAMPLES:\n",
    "        data = df_ground_truth.head(NUM_EXAMPLES)\n",
    "    else:\n",
    "        data = df_ground_truth\n",
    "\n",
    "    for i, row in data.iterrows():\n",
    "        realized_prompt = base_prompt.format(\n",
    "            role=role,\n",
    "            question=row.question,\n",
    "            options=get_options_string(row.options),\n",
    "            answer=get_answer_string(row.options, row.answer_index)\n",
    "        )\n",
    "        metadata = {\n",
    "            \"completion_request\": {\n",
    "                \"question_id\": row[\"question_id\"],\n",
    "                \"temperature\": temperature,\n",
    "                \"schema_name\": schema_name,\n",
    "                \"should_judge_ground_truth\": should_judge_ground_truth,\n",
    "                \"role\": role,\n",
    "            }\n",
    "        }\n",
    "        council_service.write_council_request(\n",
    "            realized_prompt, metadata, temperature, schema_name=schema_name,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24d2c2f-e75b-43d6-9211-830596d46292",
   "metadata": {},
   "source": [
    "#### Generate requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb708301-1cbf-4bcf-82d1-20cf6b3f2043",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in range(NUM_RUNS):\n",
    "    # STRUCTURED_OUTPUT_JUDGE_GROUND_TRUTH_COT_FIRST\n",
    "    generate_requests(prompt_name=\"so_jgt_cot1\", should_judge_ground_truth=True, schema_name=\"reasoning_then_answer\", temperature=0, role=\"student\", run=run)\n",
    "    generate_requests(prompt_name=\"so_jgt_cot1\", should_judge_ground_truth=True, schema_name=\"reasoning_then_answer\", temperature=1, role=\"student\", run=run)\n",
    "    generate_requests(prompt_name=\"so_jgt_cot1\", should_judge_ground_truth=True, schema_name=\"reasoning_then_answer\", temperature=0, role=\"expert\", run=run)\n",
    "    generate_requests(prompt_name=\"so_jgt_cot1\", should_judge_ground_truth=True, schema_name=\"reasoning_then_answer\", temperature=1, role=\"expert\", run=run)\n",
    "    \n",
    "    # STRUCTURED_OUTPUT_JUDGE_GROUND_TRUTH_COT_SECOND\n",
    "    generate_requests(prompt_name=\"so_jgt_cot2\", should_judge_ground_truth=True, schema_name=\"answer_then_reasoning\", temperature=0, role=\"student\", run=run)\n",
    "    generate_requests(prompt_name=\"so_jgt_cot2\", should_judge_ground_truth=True, schema_name=\"answer_then_reasoning\", temperature=1, role=\"student\", run=run)\n",
    "    generate_requests(prompt_name=\"so_jgt_cot2\", should_judge_ground_truth=True, schema_name=\"answer_then_reasoning\", temperature=0, role=\"expert\", run=run)\n",
    "    generate_requests(prompt_name=\"so_jgt_cot2\", should_judge_ground_truth=True, schema_name=\"answer_then_reasoning\", temperature=1, role=\"expert\", run=run)\n",
    "    \n",
    "    # STRUCTURED_OUTPUT_JUDGE_GROUND_TRUTH_NO_COT\n",
    "    generate_requests(prompt_name=\"so_jgt_cot0\", should_judge_ground_truth=True, schema_name=\"answer_only\", temperature=0, role=\"student\", run=run)\n",
    "    generate_requests(prompt_name=\"so_jgt_cot0\", should_judge_ground_truth=True, schema_name=\"answer_only\", temperature=1, role=\"student\", run=run)\n",
    "    generate_requests(prompt_name=\"so_jgt_cot0\", should_judge_ground_truth=True, schema_name=\"answer_only\", temperature=0, role=\"expert\", run=run)\n",
    "    generate_requests(prompt_name=\"so_jgt_cot0\", should_judge_ground_truth=True, schema_name=\"answer_only\", temperature=1, role=\"expert\", run=run)\n",
    "    \n",
    "    # PROMPT_JUDGE_GROUND_TRUTH_COT_FIRST\n",
    "    generate_requests(prompt_name=\"pr_jgt_cot1\", should_judge_ground_truth=True, temperature=0, role=\"student\", run=run)\n",
    "    generate_requests(prompt_name=\"pr_jgt_cot1\", should_judge_ground_truth=True, temperature=1, role=\"student\", run=run)\n",
    "    generate_requests(prompt_name=\"pr_jgt_cot1\", should_judge_ground_truth=True, temperature=0, role=\"expert\", run=run)\n",
    "    generate_requests(prompt_name=\"pr_jgt_cot1\", should_judge_ground_truth=True, temperature=1, role=\"expert\", run=run)\n",
    "    \n",
    "    # PROMPT_JUDGE_GROUND_TRUTH_COT_SECOND\n",
    "    generate_requests(prompt_name=\"pr_jgt_cot2\", should_judge_ground_truth=True, temperature=0, role=\"student\", run=run)\n",
    "    generate_requests(prompt_name=\"pr_jgt_cot2\", should_judge_ground_truth=True, temperature=1, role=\"student\", run=run)\n",
    "    generate_requests(prompt_name=\"pr_jgt_cot2\", should_judge_ground_truth=True, temperature=0, role=\"expert\", run=run)\n",
    "    generate_requests(prompt_name=\"pr_jgt_cot2\", should_judge_ground_truth=True, temperature=1, role=\"expert\", run=run)\n",
    "    \n",
    "    # PROMPT_JUDGE_GROUND_TRUTH_NO_COT\n",
    "    generate_requests(prompt_name=\"pr_jgt_cot0\", should_judge_ground_truth=True, temperature=0, role=\"student\", run=run)\n",
    "    generate_requests(prompt_name=\"pr_jgt_cot0\", should_judge_ground_truth=True, temperature=1, role=\"student\", run=run)\n",
    "    generate_requests(prompt_name=\"pr_jgt_cot0\", should_judge_ground_truth=True, temperature=0, role=\"expert\", run=run)\n",
    "    generate_requests(prompt_name=\"pr_jgt_cot0\", should_judge_ground_truth=True, temperature=1, role=\"expert\", run=run)\n",
    "    \n",
    "    # PROMPT_ANSWER_COT_FIRST\n",
    "    generate_requests(prompt_name=\"pr_ans_cot1\", should_judge_ground_truth=False, temperature=0, run=run)\n",
    "    generate_requests(prompt_name=\"pr_ans_cot1\", should_judge_ground_truth=False, temperature=1, run=run)\n",
    "    \n",
    "    # PROMPT_ANSWER_COT_SECOND\n",
    "    generate_requests(prompt_name=\"pr_ans_cot2\", should_judge_ground_truth=False, temperature=0, run=run)\n",
    "    generate_requests(prompt_name=\"pr_ans_cot2\", should_judge_ground_truth=False, temperature=1, run=run)\n",
    "    \n",
    "    # PROMPT_ANSWER_NO_COT\n",
    "    generate_requests(prompt_name=\"pr_ans_cot0\", should_judge_ground_truth=False, temperature=0, run=run)\n",
    "    generate_requests(prompt_name=\"pr_ans_cot0\", should_judge_ground_truth=False, temperature=1, run=run)\n",
    "    \n",
    "    # STRUCTURED_OUTPUT_ANSWER_COT_FIRST\n",
    "    generate_requests(prompt_name=\"so_ans_cot1\", should_judge_ground_truth=False, schema_name=\"reasoning_then_answer\", temperature=0, run=run)\n",
    "    generate_requests(prompt_name=\"so_ans_cot1\", should_judge_ground_truth=False, schema_name=\"reasoning_then_answer\", temperature=1, run=run)\n",
    "    \n",
    "    # STRUCTURED_OUTPUT_ANSWER_COT_SECOND\n",
    "    generate_requests(prompt_name=\"so_ans_cot2\", should_judge_ground_truth=False, schema_name=\"answer_then_reasoning\", temperature=0, run=run)\n",
    "    generate_requests(prompt_name=\"so_ans_cot2\", should_judge_ground_truth=False, schema_name=\"answer_then_reasoning\", temperature=1, run=run)\n",
    "    \n",
    "    # STRUCTURED_OUTPUT_ANSWER_NO_COT\n",
    "    generate_requests(prompt_name=\"so_ans_cot0\", should_judge_ground_truth=False, schema_name=\"answer_only\", temperature=0, run=run)\n",
    "    generate_requests(prompt_name=\"so_ans_cot0\", should_judge_ground_truth=False, schema_name=\"answer_only\", temperature=1, run=run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790abd86-1e75-48d4-a2b2-ee4b5a81598c",
   "metadata": {},
   "source": [
    "#### Execute Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2444c7bf-a475-4e72-b2f6-cb6d6f314ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_council.invocation.execute_council import execute\n",
    "import logging\n",
    "\n",
    "# execute(requests_dir=\"data/mmlu_pro.n10.mini.run0\")\n",
    "# execute(requests_dir=\"data/mmlu_pro.n10.mini.run1\")\n",
    "# execute(requests_dir=\"data/mmlu_pro.n10.mini.run2\")\n",
    "\n",
    "# execute(requests_dir=\"data/mmlu_pro.n100.mini.run0\")\n",
    "# execute(requests_dir=\"data/mmlu_pro.n100.mini.run1\")\n",
    "# execute(requests_dir=\"data/mmlu_pro.n100.mini.run2\")\n",
    "\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "for i in range(NUM_RUNS):\n",
    "    execute(requests_dir=\".\".join([BASE_OUTDIR, f\"run{i}\"]), models=[MODEL])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
